{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training Data and show metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "Train Columns:  Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n",
      "Label:  label\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "print(train_df.shape)\n",
    "print(\"Train Columns: \", train_df.columns)\n",
    "print(\"Label: \", train_df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Testing Data and show metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "Test Columns:  Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
      "       'pixel7', 'pixel8', 'pixel9',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=784)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "print(test_df.shape)\n",
    "print(\"Test Columns: \", test_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations so far\n",
    "There are 42,000 different images in the training dataset and 28,000 different images in the testing dataset.\n",
    "\n",
    "There are 735 columns. The first column appears to be the label (ground truth data) and the rest appear represent the image itself.\n",
    "\n",
    "The testing dataset does not have any ground truth data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset class\n",
    "\n",
    "## What are Datasets and DataLoaders?\n",
    "Processing data samples can cause code to get messy. Datasets and DataLoaders provide a way to modularize data samples and make it easier for the model to access the samples and labels that go along with the dataset. Datasets and Dataloaders provide a way to decouple interacting with the data sample from the actual training and testing of a model. Datasets stores the samples and DataLoaders provide an easy way to acccess the samples. \n",
    "\n",
    "`\n",
    "from torchvision import datasets\n",
    "`\n",
    "\n",
    "It is also possible to load current datasets with the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import os\n",
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_name, img_dir, transform=None, target_transform=None, label_name = 'label'):\n",
    "        self.img_filename = csv_name\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label_name = label_name\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.img_filename)\n",
    "        self.img_df = pd.read_csv(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_cols = [i for i in self.img_df.columns if i not in self.label_name]\n",
    "        image = self.img_df.iloc[[index]][img_cols].values\n",
    "\n",
    "        image = image.reshape(28,28)\n",
    "        image = image/255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = image.float()\n",
    "\n",
    "        if self.label_name in self.img_df.columns:\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            label = int(self.img_df.iloc[[index]][self.label_name].values)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the Distribution of target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4132\n",
       "1    4684\n",
       "2    4177\n",
       "3    4351\n",
       "4    4072\n",
       "5    3795\n",
       "6    4137\n",
       "7    4401\n",
       "8    4063\n",
       "9    4188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 4200, 42000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "indices = list(range(len(train_df)))\n",
    "\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, stratify=train_df['label'])\n",
    "\n",
    "len(train_indices), len(test_indices) , len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target values in training dataset ; \n",
      "label\n",
      "0    0.098386\n",
      "1    0.111534\n",
      "2    0.099444\n",
      "3    0.103598\n",
      "4    0.096958\n",
      "5    0.090344\n",
      "6    0.098492\n",
      "7    0.104788\n",
      "8    0.096746\n",
      "9    0.099709\n",
      "Name: count, dtype: float64\n",
      "Distribution of target values in validation dataset ; \n",
      "label\n",
      "0    0.098333\n",
      "1    0.111429\n",
      "2    0.099524\n",
      "3    0.103571\n",
      "4    0.096905\n",
      "5    0.090476\n",
      "6    0.098571\n",
      "7    0.104762\n",
      "8    0.096667\n",
      "9    0.099762\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_subset = train_df.loc[train_indices]\n",
    "val_subset = train_df.loc[test_indices]\n",
    "\n",
    "print(\"Distribution of target values in training dataset ; \")\n",
    "print( train_subset['label'].value_counts().sort_index() / train_subset['label'].value_counts().sort_index().sum() )\n",
    "\n",
    "print(\"Distribution of target values in validation dataset ; \")\n",
    "print( val_subset['label'].value_counts().sort_index() / val_subset['label'].value_counts().sort_index().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m transforms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose( [transforms\u001b[38;5;241m.\u001b[39mToTensor() , transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,)) , ] )\n\u001b[1;32m      9\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CustomMNISTDataset(csv_name\u001b[38;5;241m=\u001b[39mtrain_csv_name, img_dir\u001b[38;5;241m=\u001b[39mimg_dir, label_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m x0 , y0 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(x0\u001b[38;5;241m.\u001b[39mshape , y0)\n",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m, in \u001b[0;36mCustomMNISTDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     29\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m---> 31\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_csv_name = 'train.csv'\n",
    "test_csv_name = 'test.csv'\n",
    "img_dir = 'data/'\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor() , transforms.Normalize((0.5,), (0.5,)) , ] )\n",
    "\n",
    "train_dataset = CustomMNISTDataset(csv_name=train_csv_name, img_dir=img_dir, transform=transform, target_transform=None, label_name='label')\n",
    "x0 , y0 = train_dataset[0]\n",
    "print(x0.shape , y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
